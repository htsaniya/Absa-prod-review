{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ABSA py2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cv4722DDMXb2"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from numpy.random import shuffle\n",
        "import sys\n",
        "import os\n",
        "import csv\n",
        "import argparse\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import os, re, csv, math, codecs\n",
        "from gensim.models.fasttext import FastText"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIe-kvTqMto1"
      },
      "source": [
        "np.random.seed(1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8p8X0n0MtrD"
      },
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
        "                    help='does not use GPU')\n",
        "parser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n",
        "                    help='learning rate')\n",
        "parser.add_argument('--l2', type=float, default=0.0001, metavar='L2',\n",
        "                    help='L2 regularization weight')\n",
        "parser.add_argument('--batch-size', type=int, default=25, metavar='BS',\n",
        "                    help='batch size')\n",
        "parser.add_argument('--epochs', type=int, default=30, metavar='E',\n",
        "                    help='number of epochs')\n",
        "parser.add_argument('--hops', type=int, default=10, metavar='H',\n",
        "                    help='number of hops')\n",
        "parser.add_argument('--hidden-size', type=int, default=400, metavar='HS',\n",
        "                    help='hidden size')\n",
        "parser.add_argument('--output-size', type=int, default=400, metavar='OS',\n",
        "                    help='output size')\n",
        "parser.add_argument('--dropout-p', type=float, default=0.5, metavar='DO1',\n",
        "                    help='embedding dropout')\n",
        "parser.add_argument('--dropout-lstm', type=float, default=0.1, metavar='DO2',\n",
        "                    help='lstm dropout')\n",
        "parser.add_argument('--dataset', default='Restaurants', metavar='D',\n",
        "                    help='Laptop or Restaurants')\n",
        "args = parser.parse_args()\n",
        "print (args)\n",
        "HIDDEN_DIM          = args.hidden_size\n",
        "OUTPUT_DIM          = args.output_size\n",
        "HOP_SIZE            = args.hops\n",
        "BATCH_SIZE          = args.batch_size\n",
        "NB_EPOCH            = args.epochs\n",
        "nb_words            = 500000000\n",
        "MAX_SEQUENCE_LENGTH = 77 if args.dataset=='Laptop' else 69\n",
        "MAX_ASPECTS         = 13\n",
        "MAX_LEN_ASPECT      = 5 if args.dataset=='Laptop' else 19\n",
        "EMBEDDING_DIM       = 300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD_H-Pt0MtuA"
      },
      "source": [
        "class PreProcessing():\n",
        "\n",
        "    def __init__(self, tr_data, te_data, tokenizer, batch_size):\n",
        "        self.tag_to_ix = {\"positive\": 0, \"negative\": 1, \"neutral\": 2}\n",
        "        self.tokenizer = tokenizer # Tokenizer(num_words=nb_words)\n",
        "        self.sents=zip(*tr_data)[0]\n",
        "        self.sents1=zip(*te_data)[0]\n",
        "        self.labels=zip(*tr_data)[3]\n",
        "        self.aspects=zip(*tr_data)[1]\n",
        "        self.aspect=zip(*tr_data)[2]\n",
        "        self.batch_size=batch_size\n",
        "\n",
        "   \n",
        "    def prepare_sequence(self, seq, to_ix):\n",
        "        return [to_ix[w] for w in seq]\n",
        "\n",
        "    def keras_data_prepare(self, fit=True):\n",
        "        if fit:\n",
        "            self.tokenizer.fit_on_texts(self.sents+self.sents1)\n",
        "        sequences = self.tokenizer.texts_to_sequences(self.sents)\n",
        "        data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "        return data\n",
        "\n",
        "    def return_vars(self):\n",
        "        return self.tokenizer\n",
        "\n",
        "    def ind2vec(self, ind, N=None):\n",
        "        ind = np.asarray(ind)\n",
        "        if N is None: \n",
        "            N = ind.max() + 1\n",
        "        return (np.arange(N) == ind[:,None]).astype(int)\n",
        "\n",
        "    def prepare_data(self, data, batch_id, word_embeddings):\n",
        "        aspect_sequence=[]\n",
        "        limit = [batch_id*self.batch_size, (batch_id+1)*self.batch_size]\n",
        "        for item in self.aspects[limit[0]:limit[1]]:\n",
        "            temp=self.tokenizer.texts_to_sequences(item)\n",
        "            aspect_sequence.append(temp)\n",
        "        aspect_ = self.tokenizer.texts_to_sequences(list(self.aspect[limit[0]:limit[1]]))\n",
        "        train_temp=[]\n",
        "        j=0\n",
        "        for datam in data[limit[0]:limit[1]]:\n",
        "            train_temp.append([datam,aspect_sequence[j],aspect_[j],self.labels[limit[0]:limit[1]][j]])\n",
        "            j=j+1\n",
        "        training_data_x0=[]\n",
        "        training_data_x1=[]\n",
        "        training_data_y=[]\n",
        "        attention_mat2 =[]\n",
        "        attention_mat = []\n",
        "        for item1 in train_temp:\n",
        "          try:\n",
        "            sent, aspects, aspect, sentiment = item1[0], item1[1], item1[2], item1[3]\n",
        "            att = []\n",
        "            for i in range(0,len(sent)):\n",
        "                if sent[i] == 0:\n",
        "                    att.append(0)\n",
        "                else:\n",
        "                    att.append(1)\n",
        "\n",
        "            att_tensor = autograd.Variable(torch.FloatTensor(att) if not args.cuda else torch.cuda.FloatTensor(att),requires_grad=False)\n",
        "\n",
        "            temp_mask_sent = att_tensor.view(att_tensor.size()[0],-1).expand(-1, 2*EMBEDDING_DIM)\n",
        "            att_tensor = att_tensor.unsqueeze(0)\n",
        "            tensor = torch.LongTensor(sent) if not args.cuda else torch.cuda.LongTensor(sent)\n",
        "            sent1=autograd.Variable(tensor)\n",
        "\n",
        "            aspects1=[]\n",
        "            for item in aspects:\n",
        "              try:\n",
        "                #print aspects.index()\n",
        "                temp = torch.LongTensor(item) if not args.cuda else torch.cuda.LongTensor(item)\n",
        "                #temp = np.array(autograd.Variable(temp))\n",
        "                temp = autograd.Variable(temp)\n",
        "                temp = word_embeddings(temp)\n",
        "#                torch.from_numpy(temp)\n",
        "                temp = torch.mean(temp,dim=0)\n",
        "                aspects1.append(temp)\n",
        "              except:\n",
        "                continue\n",
        "\n",
        "            aspect = torch.LongTensor(aspect) if not args.cuda else torch.cuda.LongTensor(aspect)\n",
        "            aspect = autograd.Variable(aspect)\n",
        "\n",
        "            label=self.prepare_sequence(sentiment, self.tag_to_ix)\n",
        "\n",
        "            embeds=word_embeddings(sent1)\n",
        "\n",
        "            #aspect = torch.LongTensor(aspect)\n",
        "            #aspect = autograd.Variable(aspect)\n",
        "            aspect1= word_embeddings(aspect)\n",
        "            aspect1= torch.mean(aspect1,dim=0)\n",
        "            aspect1 = aspect1.expand(len(sent),-1)\n",
        "\n",
        "            sepr = []\n",
        "            att2 = []\n",
        "            for i in range(0,MAX_ASPECTS-len(aspects)):\n",
        "                sepr.append(autograd.Variable(torch.zeros((MAX_SEQUENCE_LENGTH,2*EMBEDDING_DIM)).type(ftype).unsqueeze(0)))\n",
        "                att2.append(0)\n",
        "\n",
        "            for item in aspects1:\n",
        "                item = item.expand(len(sent),-1)\n",
        "                sepr.append(torch.mul(torch.cat([embeds,item],dim=1),temp_mask_sent).unsqueeze(0))\n",
        "                att2.append(1)\n",
        "\n",
        "            aspect1 = torch.mul(torch.cat([embeds,aspect1],dim=1),temp_mask_sent)\n",
        "\n",
        "            att2_tensor = autograd.Variable(torch.FloatTensor(att2) if not args.cuda else torch.cuda.FloatTensor(att2),requires_grad=False).unsqueeze(0)\n",
        "            sepr_tensor=torch.cat(sepr,dim=0)\n",
        "            sepr_tensor = sepr_tensor.unsqueeze(0)\n",
        "            training_data_x0.append(sepr_tensor)\n",
        "            training_data_x1.append(aspect1.unsqueeze(0))\n",
        "            training_data_y.append(label)\n",
        "            attention_mat2.append(att2_tensor)\n",
        "            attention_mat.append(att_tensor)\n",
        "            #attd = np.array(attention_mat2)\n",
        "            #attd = attd.astype(np.float32)\n",
        "            #attention_mat2 = torch.from_numpy(attd)\n",
        "          except:\n",
        "            continue\n",
        "        att2_var = torch.cat(attention_mat2,dim=0)\n",
        "        att_var = torch.cat(attention_mat, dim =0 )\n",
        "        return torch.cat(training_data_x0,dim=0), torch.cat(training_data_x1,dim=0), autograd.Variable(torch.LongTensor(to_categorical(training_data_y,3)) if not args.cuda else torch.cuda.LongTensor(to_categorical(training_data_y,3))),att2_var, att_var\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFT9sFZOMtwK"
      },
      "source": [
        "class AttnRNN(nn.Module):\n",
        "    def __init__(self, hop_size, batch_size, input_size, sent_size, output_size,\n",
        "            dropout_p=args.dropout_p, dropout_lstm = args.dropout_lstm,\n",
        "            max_length=MAX_SEQUENCE_LENGTH):\n",
        "        super(AttnRNN, self).__init__()\n",
        "        self.hop_size = hop_size\n",
        "        self.batch_size = batch_size\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.sent_size = sent_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.dropout_lstm = dropout_lstm\n",
        "        self.max_length = max_length\n",
        "        self.hidden_sentence_gru = self.init_hidden2(self.batch_size)\n",
        "        self.hidden_aspect_gru = self.init_hidden(self.batch_size)\n",
        "        self.hidden_aspect_write_gru=self.init_hidden(self.batch_size)\n",
        "        #self.hidden_aspect_repr_gru = self.init_aspect_hidden(self.batch_size)\n",
        "        self.sentence_gru = nn.GRU(self.input_size*2, self.sent_size)\n",
        "        self.aspect_gru = nn.GRU(self.sent_size, self.output_size)\n",
        "        self.aspect_write_gru = nn.GRU(self.output_size, self.output_size)\n",
        "        # self.aspect_write_gru = nn.GRU(self.output_size, self.output_size/2,\n",
        "        #         bidirectional=True)\n",
        "        #self.aspect_repr_gru = nn.GRU(self.input_size*2, self.sent_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.dropout2 = nn.Dropout(self.dropout_lstm)\n",
        "        self.attn = nn.Linear(self.sent_size, 1)\n",
        "        self.attn2 = nn.Linear(1, 1)\n",
        "        self.affine = nn.Linear(self.output_size,3)\n",
        "        self.dimproj = nn.Linear(self.sent_size, self.output_size)\n",
        "\n",
        "    def forward(self, sents, aspects, attention_mat1, attention_mat2, batch_size):\n",
        "        sents=sents.permute(1,2,0,3) # -> (aspect, seq, batch, embed*2)\n",
        "        outputs = []\n",
        "        alphas=[]\n",
        "        for sent_asp in sents:\n",
        "            embedded = self.dropout(sent_asp)\n",
        "            output, hidden_sentence_gru = self.sentence_gru(embedded, self.hidden_sentence_gru)\n",
        "            #print attention_mat1.size()\n",
        "            temp_attention_mat1 = attention_mat1.view(attention_mat1.size()[0],attention_mat1.size()[1],1).expand(-1,-1,output.size()[2])\n",
        "            #print temp_attention_mat1.size()\n",
        "            #sys.exit(1)\n",
        "            output = torch.mul(output.permute(1,0,2),temp_attention_mat1)\n",
        "            output = self.dropout2(output)\n",
        "            #print output.size()\n",
        "           # sys.exit(1)\n",
        "            attn_weights = F.softmax(\n",
        "                self.attn(output.permute(1,0,2)), dim=0)\n",
        "            #print attn_weights.size()\n",
        "            #print attention_mat1.size()\n",
        "            #sys.exit(1)\n",
        "            masked_attn_weights = torch.mul(attn_weights.squeeze().permute(1,0),attention_mat1)\n",
        "            #print masked_attn_weights.size()\n",
        "            _sums = masked_attn_weights.sum(-1).unsqueeze(1).expand(-1,masked_attn_weights.size()[1])\n",
        "            #print _sums.size()\n",
        "            attentions = masked_attn_weights.div(_sums).unsqueeze(1).permute(2,0,1)\n",
        "            alphas.append(attentions.permute(1,2,0).unsqueeze(0))\n",
        "\n",
        "            #print attentions.permute(1,0,2).squeeze()[47].sum()\n",
        "            #print attn_weights.permute(1,0,2)\n",
        "            attn_applied = torch.bmm(attentions.permute(1,2,0),\n",
        "                                 output).squeeze()\n",
        "            output = F.relu(attn_applied)\n",
        "            outputs.append(output.unsqueeze(0))\n",
        "\n",
        "        aspec_rep = torch.cat(outputs, dim=0)\n",
        "        output, hidden_aspect_gru = self.aspect_gru(aspec_rep,self.hidden_aspect_gru)\n",
        "\n",
        "        temp_attention_mat2 = attention_mat2.view(attention_mat2.size()[0],attention_mat2.size()[1],1).expand(-1,-1,output.size()[2])\n",
        "\n",
        "        output = torch.mul(output.permute(1,0,2),temp_attention_mat2)\n",
        "        output = self.dropout2(output)\n",
        "\n",
        "        aspects = aspects.permute(1,0,2)\n",
        "        outputa_,hida_ = self.sentence_gru(aspects,self.hidden_sentence_gru)\n",
        "        temp_attention_mat3 = attention_mat1.view(attention_mat1.size()[0],attention_mat1.size()[1],1).expand(-1,-1,outputa_.size()[2])\n",
        "        outputa_ = torch.mul(outputa_.permute(1,0,2),temp_attention_mat3)\n",
        "        attn_weights_ = F.softmax(\n",
        "                self.attn(outputa_.permute(1,0,2)), dim=0)\n",
        "        masked_attn_weights_ = torch.mul(attn_weights_.squeeze().permute(1,0),attention_mat1)\n",
        "        _sums_ = masked_attn_weights_.sum(-1).unsqueeze(1).expand(-1,masked_attn_weights_.size()[1])\n",
        "        attentions_ = masked_attn_weights_.div(_sums_).unsqueeze(1).permute(2,0,1)\n",
        "        attn_applied_ = torch.bmm(attentions_.permute(1,2,0),\n",
        "                                 outputa_).squeeze()\n",
        "        if self.sent_size == self.output_size:\n",
        "                    asp_proj = attn_applied_.unsqueeze(1)\n",
        "        else:\n",
        "            asp_proj = self.dimproj(attn_applied_).unsqueeze(1)\n",
        "        #print \"Output size,\", output.size()\n",
        "        #print \"Aspect proj size,\", asp_proj.size()\n",
        "\n",
        "        output=output.permute(0,2,1)\n",
        "\n",
        "        betas = []\n",
        "        for i in range(0,self.hop_size):\n",
        "            match = torch.bmm(asp_proj,output).permute(2,0,1)\n",
        "\n",
        "\n",
        "            attn_weights2 = F.softmax(\n",
        "                    self.attn2(match), dim=0)\n",
        "            #print attn_weights\n",
        "            self.hidden_aspect_write_gru=self.init_hidden(batch_size)\n",
        "            output_w, hidden_aspect_write_gru = \\\n",
        "            self.aspect_write_gru(output.permute(2,0,1),self.hidden_aspect_write_gru)\n",
        "\n",
        "            output_w = torch.mul(output_w.permute(1,0,2),temp_attention_mat2)\n",
        "            output_w = self.dropout2(output_w)\n",
        "\n",
        "\n",
        "            masked_attn_weights2 = torch.mul(attn_weights2.squeeze().permute(1,0),attention_mat2)\n",
        "            #print masked_attn_weights.size()\n",
        "            _sums2 = masked_attn_weights2.sum(-1).unsqueeze(1).expand(-1,masked_attn_weights2.size()[1])\n",
        "            #print _sums.size()\n",
        "            attentions2 = masked_attn_weights2.div(_sums2).unsqueeze(1).permute(2,0,1)\n",
        "\n",
        "            #print output_w.size()\n",
        "            #print attn_weights.size()\n",
        "\n",
        "            #print attentions2.squeeze().permute(1,0)[0].sum()\n",
        "\n",
        "            attn_applied = torch.bmm(attentions2.permute(1,2,0), output_w.permute(0,1,2)).squeeze()\n",
        "\n",
        "            betas.append(attentions2.permute(1,2,0))\n",
        "\n",
        "            #print \"attn_applied size\", attn_applied.size()\n",
        "\n",
        "            query = asp_proj.view(asp_proj.size()[0],asp_proj.size()[2])\n",
        "\n",
        "            #print \"query size\", query.size()\n",
        "\n",
        "            final_output = torch.add(attn_applied, query)\n",
        "\n",
        "            #print final_output.size()\n",
        "\n",
        "            final_output = F.relu(final_output)\n",
        "            asp_proj = final_output.unsqueeze(1)\n",
        "            #output = output_w.permute(1,2,0)\n",
        "            output = output_w.permute(0,2,1)\n",
        "            #print\"output size final-----\", output.size()\n",
        "        asp_proj = F.log_softmax(self.affine(asp_proj.squeeze()),dim=1)\n",
        "        #asp_proj = self.affine(asp_proj.squeeze())\n",
        "        return asp_proj, betas, torch.cat(alphas,0)\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "\n",
        "        return autograd.Variable(torch.zeros(1, batch_size,\n",
        "            self.output_size).type(ftype))\n",
        "\n",
        "    def init_hidden_memnet(self, batch_size):\n",
        "\n",
        "        return autograd.Variable(torch.zeros(2, batch_size,\n",
        "            self.output_size/2).type(ftype))\n",
        "\n",
        "   # def init_aspect_hidden(self, batch_size):\n",
        "   #    return autograd.Variable(torch.zeros(1, batch_size, self.sent_size))\n",
        "\n",
        "    def init_hidden2(self, batch_size):\n",
        "\n",
        "        return autograd.Variable(torch.zeros(1, batch_size,\n",
        "            self.sent_size).type(ftype))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RgXJP0lNZjm"
      },
      "source": [
        "def Glove(GLOVE_DIR):\n",
        "    embeddings_index = {}\n",
        "    f = open(os.path.join(GLOVE_DIR, 'glove.6B.300d.txt'))\n",
        "    #f = open(os.path.join(GLOVE_DIR, 'ex.txt'))\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "    f.close()\n",
        "    return embeddings_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPDgXlElNZl_"
      },
      "source": [
        "def fasttext(fasttext_dir):\n",
        "    embeddings_index = {}\n",
        "    f = codecs.open(os.path.join(fasttext_dir, 'wiki.id.vec'))\n",
        "    #f = open(os.path.join(fasttext_dir, 'ft.vec'))\n",
        "    \n",
        "    for line in tqdm(f):\n",
        "      values = line.rstrip().rsplit(' ')\n",
        "      word = values[0]\n",
        "      coefs = np.asarray(values[1:], dtype='float32')\n",
        "      embeddings_index[word] = coefs\n",
        "    f.close()\n",
        "    return embeddings_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m67uhH6zNi2x"
      },
      "source": [
        "def index_word_embeddings(word_index, embeddings_index):\n",
        "  #  embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
        "  #  for word, i in word_index.items():\n",
        "  #    embedding_vector = embeddings_index.get(word)\n",
        "  #    if embedding_vector is not None:\n",
        "  #      embedding_matrix[i] = embedding_vector\n",
        "\n",
        "    #words_not_found = []\n",
        "      embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
        "      for word, i in word_index.items():\n",
        "        try:\n",
        "          embedding_vector = embeddings_index.get(word)\n",
        "          if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "          #else:\n",
        "       # words_not_found.append(word)\n",
        "        except:\n",
        "          continue\n",
        "      return embedding_matrix\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYHo6bR4Ni5k"
      },
      "source": [
        "def get_accuracy(truth, pred):\n",
        "     assert len(truth)==len(pred)\n",
        "     right = 0\n",
        "     for i in range(len(truth)):\n",
        "         if truth[i]==pred[i]:\n",
        "             right += 1.0\n",
        "     return right/len(truth)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beZmJ4g329iA"
      },
      "source": [
        "def accuracy(preds, true):\n",
        "    return sum(1 for x,y in zip(preds,true) if x == y) / float(len(preds))*100."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwBnquTtNoUA"
      },
      "source": [
        "def train(onea):\n",
        "    tokenizer = Tokenizer(500000000)\n",
        "    prep = PreProcessing(training_data,test_data,tokenizer,BATCH_SIZE)\n",
        "    data = prep.keras_data_prepare()\n",
        "\n",
        "    we=fasttext(fasttext_dir=\"/content/drive/MyDrive/Dataset/\")\n",
        "    #we = Glove(GLOVE_DIR = '/content/drive/MyDrive/Medical image Reporting/glove/')\n",
        "    ei=index_word_embeddings(tokenizer.word_index,we)\n",
        "    #embeddings = nn.Embedding(len(tokenizer.word_index)+1, EMBEDDING_DIM,padding_idx=0)\n",
        "    #word_embeddings = embeddings(ei) \n",
        "    #dataf = ft.items()\n",
        "    #result = list(dataf)\n",
        "    #we = np.array(result)\n",
        "    word_embeddings = nn.Embedding(len(tokenizer.word_index)+1, EMBEDDING_DIM,padding_idx=0)\n",
        "    word_embeddings.weight = nn.Parameter(torch.FloatTensor(ei) if not args.cuda else torch.cuda.FloatTensor(ei))\n",
        "    word_embeddings.weight.requires_grad = False\n",
        "    print (\"Embeddings loaded....\")\n",
        "\n",
        "    model = AttnRNN(HOP_SIZE, BATCH_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
        "    if args.cuda:\n",
        "        model.cuda()\n",
        "    loss_function = nn.NLLLoss()\n",
        "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, [x for x in\n",
        "        model.parameters()] + [word_embeddings.weight]), lr = args.lr,\n",
        "        weight_decay = args.l2)\n",
        "\n",
        "    batch_count = int(np.ceil(len(training_data)/float(BATCH_SIZE)))\n",
        "\n",
        "    for i in range(NB_EPOCH):\n",
        "        start_time = time.time()\n",
        "\n",
        "        loss_tot = []\n",
        "        true_label=[]\n",
        "        pred_res=[]\n",
        "        model.train()\n",
        "        for batch_id in range(batch_count):\n",
        "            optimizer.zero_grad()\n",
        "            bdata_x0, bdata_x1, bdata_y, attention_mat2, attention_mat1 = prep.prepare_data(data, batch_id, word_embeddings)\n",
        "            model.hidden_sentence_gru = model.init_hidden2(bdata_x0.size()[0])\n",
        "            model.hidden_aspect_gru = model.init_hidden(bdata_x0.size()[0])\n",
        "            model.hidden_aspect_write_gru = model.init_hidden(bdata_x0.size()[0])\n",
        "            #model.hidden_aspect_repr_gru = model.init_aspect_hidden(bdata_x0.size()[0])\n",
        "\n",
        "\n",
        "            prediction, _, _ = model(bdata_x0,bdata_x1, attention_mat1, attention_mat2, bdata_x0.size()[0])\n",
        "            loss = loss_function(prediction, torch.max(bdata_y, 1)[1])\n",
        "            # print \"Loss \", i, loss.data[0]\n",
        "            loss_tot.append(loss.data[0])\n",
        "            \n",
        "            pred_label = prediction.data.max(1)[1].cpu().numpy()\n",
        "            pred_res += [x for x in pred_label]\n",
        "            true_data = torch.max(bdata_y, 1)[1].cpu()\n",
        "            true_label+= [x for x in true_data.data]\n",
        "            loss.backward()\n",
        "            # print word_embeddings.weight.grad\n",
        "            optimizer.step()\n",
        "\n",
        "        preds,true,test_loss = test(test_data, model, tokenizer,\n",
        "                word_embeddings, loss_function, i,onea)\n",
        "\n",
        "        # for k in range(1,39):\n",
        "        #     print '%s, %s, %d, %d' % (test_data[-k][0],test_data[-k][2],true[-k],preds[-k])\n",
        "\n",
        "        print ('Epoch %d train_loss %.4f train_acc %.2f test_loss %.4f test_acc %.2f time %.2f' % (i+1, np.mean(loss_tot), accuracy(pred_res, true_label), test_loss, accuracy(preds,true), time.time()-start_time))\n",
        "        # import ipdb;ipdb.set_trace()\n",
        "        mul = set(range(len(true)))-set(onea)\n",
        "        print ('single_aspect %.2f mul_aspect %.2f' % (accuracy([preds[idx] for idx in onea],[true[idx] for idx in onea]), accuracy([preds[idx] for idx in mul],[true[idx] for idx in mul])))\n",
        "\n",
        "    return model, tokenizer, word_embeddings\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSoVpItMNoWX"
      },
      "source": [
        "def test(test_data, model, tokenizer, word_embeddings, loss_function, epoch, onea):\n",
        "    prep = PreProcessing(test_data,training_data,tokenizer,BATCH_SIZE)\n",
        "    data = prep.keras_data_prepare(False)\n",
        "\n",
        "    model.eval()\n",
        "    true_label=[]\n",
        "    loss_tot = []\n",
        "    pred_res=[]\n",
        "\n",
        "    batch_count = int(np.ceil(len(test_data)/float(BATCH_SIZE)))\n",
        "\n",
        "    # print batch_count, len(test_data)\n",
        "    betas = []\n",
        "    alphas = []\n",
        "    for batch_id in range(batch_count):\n",
        "            bdata_x0, bdata_x1, bdata_y, attention_mat2, attention_mat1 = prep.prepare_data(data, batch_id, word_embeddings)\n",
        "            model.hidden_sentence_gru = model.init_hidden2(bdata_x0.size()[0])\n",
        "            model.hidden_aspect_gru = model.init_hidden(bdata_x0.size()[0])\n",
        "            model.hidden_aspect_write_gru = model.init_hidden(bdata_x0.size()[0])\n",
        "            #model.hidden_aspect_repr_gru = model.init_aspect_hidden(bdata_x0.size()[0])\n",
        "\n",
        "            preds, beta , alpha = model(bdata_x0,bdata_x1, attention_mat1, attention_mat2, bdata_x0.size()[0])\n",
        "            betas +=[dat.data.cpu().numpy() for dat in beta]\n",
        "            alphas.append(alpha.data.cpu().numpy())\n",
        "            loss = loss_function(preds, torch.max(bdata_y, 1)[1])\n",
        "            loss_tot.append(loss.data[0])\n",
        "            pred_label = preds.data.max(1)[1].cpu().numpy()\n",
        "            pred_res += [x for x in pred_label]\n",
        "            true_data = torch.max(bdata_y, 1)[1].cpu()\n",
        "            true_label+= [x for x in true_data.data]\n",
        "    # with open('betas_%d.p'%epoch,'wb') as fp:\n",
        "    #     cPickle.dump(betas,fp)\n",
        "    # with open('alphas_%d.p'%epoch,'wb') as fp:\n",
        "    #     cPickle.dump(alphas,fp)\n",
        "    return pred_res, true_label, np.mean(loss_tot)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuELAZfY24cu"
      },
      "source": [
        "def csv_reader(file):\n",
        "    data =[]\n",
        "    with open(file, 'rb') as csvfile:\n",
        "        aspectreader = csv.reader(csvfile, delimiter=',')\n",
        "        for row in aspectreader:\n",
        "#            print row\n",
        "            sent = row[0].lower()\n",
        "            nb_aspects = int(row[1])\n",
        "            aspects = [x.replace(\"'\",\"\").replace('[',\"\").replace(\"\\\"\",\"\").replace(']',\"\").strip().lower() for x in row[2].split(\",\")]\n",
        "            sentiments = [x.strip().replace(\"'\",\"\").replace('[',\"\").replace(\"\\\"\",\"\").replace(']',\"\").lower() for x in row[3].split(\",\")]\n",
        "            for i in range(0,nb_aspects):\n",
        "#                print nb_aspects,len(aspects)\n",
        "              #if i> len(aspects):\n",
        "               # nb_aspects-1\n",
        "                datam = (sent,aspects , aspects[i], [sentiments[i]])\n",
        "                data.append(datam)\n",
        "              #else:\n",
        "               # datam = (sent,aspects , aspects[i], [sentiments[i]])\n",
        "                #data.append(datam)\n",
        "    return data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dfQIAK_29ms"
      },
      "source": [
        "if __name__=='__main__':\n",
        "\n",
        "    # parser = argparse.ArgumentParser()\n",
        "    # parser.add_argument('--no-cuda', action='store_true', default=False,\n",
        "    #                     help='does not use GPU')\n",
        "    # parser.add_argument('--dataset', default='Laptop', metavar='D',\n",
        "    #                     help='Laptop or Restaurants')\n",
        "    # args = parser.parse_args()\n",
        "\n",
        "    args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "    if args.cuda:\n",
        "        print ('Running on GPU')\n",
        "        torch.cuda.manual_seed(1)\n",
        "        ftype = torch.cuda.FloatTensor\n",
        "    else:\n",
        "        print ('Running on CPU')\n",
        "        torch.manual_seed(1)\n",
        "        ftype = torch.FloatTensor\n",
        "    training_data = csv_reader('final_'+args.dataset+'_train.csv')\n",
        "    test_data = csv_reader('final_'+args.dataset+'_test.csv')\n",
        "    shuffle(training_data)\n",
        "    # print training_data[0]\n",
        "    # print np.max([len(x.split()) for x in zip(*training_data)[0]+zip(*test_data)[0]])\n",
        "    # print np.max([len(x.split()) for x in zip(*training_data)[2]+zip(*test_data)[2]])\n",
        "    # print np.max([len(x) for x in zip(*training_data)[1]+zip(*test_data)[1]])\n",
        "    # sys.exit(0)\n",
        "\n",
        "    onea = [i for i,(s,a,aa,l) in enumerate(test_data) if len(a)==1]\n",
        "    tonea = [i for i,(s,a,aa,l) in enumerate(training_data) if len(a)==1]\n",
        "    print (len(onea),len(test_data)-len(onea))\n",
        "    print (len(tonea),len(training_data)-len(tonea))\n",
        "    model, tokenizer, word_embeddings = train(onea)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr8Tnrez3Cv-"
      },
      "source": [
        "from sklearn import metrics\n",
        "preds[] = preds[idx] for idx in onea\n",
        "true[] = true[idx] for idx in onea\n",
        "print(metrics.accuracy_score(true[],preds[]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}